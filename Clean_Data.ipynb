{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkey = input(\"Enter API Key \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"Heart_Disease_Mortality_Data_Among_US_Adults_35_by_State_Territory_and_County.csv\"\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting Useless Columns\n",
    "df = df.drop(columns= [\"Year\", \"GeographicLevel\",\"DataSource\",\"Class\",'Topic',\"Data_Value_Type\",'Data_Value_Footnote_Symbol','Data_Value_Footnote','StratificationCategory1','StratificationCategory2','TopicID','LocationID','Data_Value_Unit'])\n",
    "df = df.rename(columns={\"LocationAbbr\": \"State\", \"LocationDesc\": \"County\", \"Data_Value\": \"Value\", \"Stratification1\": \"Gender\", \"Stratification2\": \"Race/Ethnicity\", \"Location 1\": \"LatLng\"})\n",
    "\n",
    "# Dropping Rows that are empty\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "# Adding df1 for Google API Purpose, copy of df\n",
    "df1 = df\n",
    "\n",
    "# Getting 10% of dataframe\n",
    "a = len(df)\n",
    "rows = .1 *a\n",
    "rows\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = df[\"LatLng\"].str.split(\"(\", n = 1, expand = True) \n",
    "split = split[1].str.split(\", \", n = 1, expand = True) \n",
    "splitLng = split[1].str.split(\")\", n = 1, expand = True) \n",
    "# making seperate first name column from new data frame \n",
    "df[\"Lat\"]= split[0] \n",
    "  \n",
    "# making seperate last name column from new data frame \n",
    "df[\"Lng\"]= splitLng[0] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "df = df.drop(columns =[\"LatLng\"]) \n",
    "\n",
    "# df display \n",
    "\n",
    "df.head()\n",
    "print(df[\"Race/Ethnicity\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by county\n",
    "county = pd.DataFrame(df)\n",
    "county = county.loc[county['Gender']== \"Overall\"]\n",
    "county = county.loc[county['Race/Ethnicity'] == \"Overall\"]\n",
    "\n",
    "county = county.sort_values(['Value'],ascending=False)\n",
    "#.groupby(['State', 'County'])\n",
    "\n",
    "county.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county.to_csv(\"countydata.csv\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 10,
>>>>>>> e2e16e85d109369a495be126f132b79700f88ce9
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by Ethnicity (White)\n",
    "white = pd.DataFrame(df)\n",
    "white = white.loc[white['Gender']== \"Overall\"]\n",
    "white = white.loc[white['Race/Ethnicity'] == \"White\"]\n",
    "white = white.sort_values(['State'])\n",
    "#.groupby(['State', 'County'])\n",
    "#white.head()\n",
    "white.to_csv(\"whitedata.csv\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 11,
>>>>>>> e2e16e85d109369a495be126f132b79700f88ce9
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by Ethnicity (Black)\n",
    "black = pd.DataFrame(df)\n",
    "black = black.loc[black['Gender']== \"Overall\"]\n",
    "black = black.loc[black['Race/Ethnicity'] == \"Black\"]\n",
    "black = black.sort_values(['State'])\n",
    "#.groupby(['State', 'County'])\n",
    "#black.head()\n",
    "black.to_csv(\"blackdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 12,
>>>>>>> e2e16e85d109369a495be126f132b79700f88ce9
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by Ethnicity (Hispanic)\n",
    "hispanic = pd.DataFrame(df)\n",
    "hispanic = hispanic.loc[hispanic['Gender']== \"Overall\"]\n",
    "hispanic = hispanic.loc[hispanic['Race/Ethnicity'] == \"Hispanic\"]\n",
    "hispanic = hispanic.sort_values(['State'])\n",
    "#.groupby(['State', 'County'])\n",
    "hispanic.to_csv(\"hispanicdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 13,
>>>>>>> e2e16e85d109369a495be126f132b79700f88ce9
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by Ethnicity (Indian)\n",
    "na = pd.DataFrame(df)\n",
    "na = na.loc[na['Gender']== \"Overall\"]\n",
    "na = na.loc[na['Race/Ethnicity'] == \"American Indian and Alaskan Native\"]\n",
    "na = na.sort_values(['State'])\n",
    "#.groupby(['State', 'County'])\n",
<<<<<<< HEAD
    "na.head()"
=======
    "Indian.to_csv(\"indiandata.csv\")"
>>>>>>> e2e16e85d109369a495be126f132b79700f88ce9
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 14,
>>>>>>> e2e16e85d109369a495be126f132b79700f88ce9
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by Ethnicity (Asian)\n",
    "Asian = pd.DataFrame(df)\n",
    "Asian = Asian.loc[Asian['Gender']== \"Overall\"]\n",
    "Asian = Asian.loc[Asian['Race/Ethnicity'] == \"Asian and Pacific Islander\"]\n",
    "Asian = Asian.sort_values(['State'])\n",
    "#.groupby(['State', 'County'])\n",
    "\n",
    "Asian.to_csv(\"asiandata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting Top 10%\n",
    "top10 = county.iloc[range(0,round(rows)),]\n",
    "top10.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting Bottom 10%\n",
    "bottom10= county.iloc[range(len(county)- round(rows), len(county))]\n",
    "bottom10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10% for each Race/Ethnicity\n",
    "\n",
    "white_top10 = pd.DataFrame()\n",
    "black_top10 = pd.DataFrame()\n",
    "hispanic_top10 = pd.DataFrame()\n",
    "Asian_top10 = pd.DataFrame()\n",
    "na_top10 = pd.DataFrame()\n",
    "for i in top10['County']:\n",
    "    sorted_white = white.loc[white['County'] == i]\n",
    "    white_top10 = white_top10.append(sorted_white)\n",
    "    \n",
    "    sorted_black = black.loc[black['County'] == i]\n",
    "    black_top10 = black_top10.append(sorted_black)\n",
    "    \n",
    "    his = hispanic.loc[hispanic['County'] == i]\n",
    "    hispanic_top10 = hispanic_top10.append(his)\n",
    "    \n",
    "    asian = Asian.loc[Asian['County'] == i]\n",
    "    Asian_top10 = Asian_top10.append(asian)\n",
    "    \n",
    "    Na = na.loc[Indian['County'] == i]\n",
    "    na_top10 = na_top10.append(In)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bottom 10 for each Race/Ethnicity\n",
    "\n",
    "white_b10 = pd.DataFrame()\n",
    "black_b10 = pd.DataFrame()\n",
    "hispanic_b10 = pd.DataFrame()\n",
    "Asian_b10 = pd.DataFrame()\n",
    "Indian_b10 = pd.DataFrame()\n",
    "for i in top10['County']:\n",
    "    sorted_white = white.loc[white['County'] == i]\n",
    "    white_b10 = white_b10.append(sorted_white)\n",
    "    \n",
    "    sorted_black = black.loc[black['County'] == i]\n",
    "    black_b10 = black_b10.append(sorted_black)\n",
    "    \n",
    "    his = hispanic.loc[hispanic['County'] == i]\n",
    "    hispanic_b10 = hispanic_b10.append(his)\n",
    "    \n",
    "    asian = Asian.loc[Asian['County'] == i]\n",
    "    Asian_b10 = Asian_b10.append(asian)\n",
    "    \n",
    "    In = Indian.loc[Indian['County'] == i]\n",
    "    Indian_b10 = Indian_b10.append(In)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for census pulling\n",
    "\n",
    "# **********************************************\n",
    "# Don't forget to jump into PythonData\n",
    "# **********************************************\n",
    "\n",
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from census import Census\n",
    "import gmaps\n",
    "import time\n",
    "\n",
    "# Census & gmaps API Keys\n",
    "# census_api = input(\"What's your Census API key?\")\n",
    "# gmap_api = input (\"What's your Gmaps API key?\")\n",
    "census_api = \"85ac64b6b5a9c0901b00329d1ef41f0c53ccfc98\"\n",
    "c = Census(census_api, year=2014)\n",
    "gmap_api = \"AIzaSyCS1nhiSTclbrQT2_WtJHFvRLZ_eeuh5iI\"\n",
    "\n",
    "# Configure gmaps\n",
    "# gmaps.configure(api_key=gkey)\n",
    "\n",
    "# Run Census Search to retrieve data on all zip codes (2013 ACS5 Census)\n",
    "# See: https://github.com/CommerceDataService/census-wrapper for library documentation\n",
    "# See: https://gist.github.com/afhaque/60558290d6efd892351c4b64e5c01e9b for labels\n",
    "census_data = c.acs5.get((\"NAME\", \"B17001A_002E\", \"B17001B_002E\", \"B17001C_002E\",\n",
    "                          \"B17001D_002E\",\"B17001E_002E\", \"B17001G_002E\", \n",
    "                          \"B17001I_002E\", \"B01003_001E\"),{'for': 'county:*'})\n",
    "\n",
    "# Convert to DataFrame\n",
    "census_pd = pd.DataFrame(census_data)\n",
    "census_pd\n",
    "\n",
    "# Column Reordering\n",
    "census_pd = census_pd.rename(columns={\"B17001A_002E\": \"poverty_White\", \n",
    "                                        \"B17001B_002E\": \"poverty_Black\", \n",
    "                                        \"B17001C_002E\": \"poverty_AmerInd\",\n",
    "                                        \"B17001D_002E\": \"poverty_Asian\",\n",
    "                                        \"B17001E_002E\": \"poverty_NatHaw\", \n",
    "                                        \"B17001G_002E\": \"poverty_Multi\", \n",
    "                                        \"B17001I_002E\": \"poverty_Hisp\",\n",
    "                                        \"B01003_001E\" : \"totalpop\",\n",
    "                                          \"NAME\": \"Name\", \"county\": \"Country\"})\n",
    "\n",
    "# Divide the \"name\" into its county and state separately. \n",
    "census_pd[\"CountyName\"] = \"\"\n",
    "census_pd[\"StateName\"] = \"\"\n",
    "for i in range(0,len(census_pd)):\n",
    "    st = census_pd.Name[i].split(\",\")\n",
    "    census_pd.CountyName[i] = st[0]\n",
    "    census_pd.StateName[i] = st[1]\n",
    "\n",
    "# Add in Poverty Rate (Poverty Count / Population)\n",
    "census_pd[\"white_rate\"] = 100 * (census_pd[\"poverty_White\"].astype(int) / census_pd[\"totalpop\"].astype(int))\n",
    "census_pd[\"black_rate\"] = 100 * (census_pd[\"poverty_Black\"].astype(int) / census_pd[\"totalpop\"].astype(int))\n",
    "census_pd[\"amerind_rate\"] = 100 * (census_pd[\"poverty_AmerInd\"].astype(int) / census_pd[\"totalpop\"].astype(int))\n",
    "census_pd[\"asian_rate\"] = 100 * (census_pd[\"poverty_Asian\"].astype(int) / census_pd[\"totalpop\"].astype(int))\n",
    "census_pd[\"nathaw_rate\"] = 100 * (census_pd[\"poverty_NatHaw\"].astype(int) / census_pd[\"totalpop\"].astype(int))\n",
    "census_pd[\"multi_rate\"] = 100 * (census_pd[\"poverty_Multi\"].astype(int) / census_pd[\"totalpop\"].astype(int))\n",
    "census_pd[\"hisp_rate\"] = 100 * (census_pd[\"poverty_Hisp\"].astype(int) / census_pd[\"totalpop\"].astype(int))\n",
    "\n",
    "\n",
    "### Heat Mapping?\n",
    "# Configure gmaps with API key\n",
    "gmaps.configure(api_key=gmap_api)\n",
    "# Store 'Lat' and 'Lng' into  locations \n",
    "locations = county[[\"County\", \"Lat\", \"Lng\"]]\n",
    "locations.Lat = locations.Lat.astype(float)\n",
    "locations.Lng = locations.Lng.astype(float)\n",
    "# Convert Poverty Rate to float and store\n",
    "# HINT: be sure to handle NaN values\n",
    "poverty_rate_white = census_pd[[\"CountyName\", \"white_rate\"]]\n",
    "poverty_rate_white= poverty_rate_white.rename(columns = {\"CountyName\": \"County\"})\n",
    "poverty_rate_white.head()\n",
    "\n",
    "pov_whitemap = pd.merge(locations, poverty_rate_white, on = \"County\", how = \"inner\")\n",
    "\n",
    "# Create a poverty Heatmap layer\n",
    "White_povmap = gmaps.figure()\n",
    "\n",
    "heat_layer_white = gmaps.heatmap_layer(pov_whitemap[[\"Lat\", \"Lng\"]], weights=pov_whitemap[\"white_rate\"], \n",
    "                                 dissipating=False, max_intensity=100,\n",
    "                                 point_radius = 1)\n",
    "\n",
    "# Adjust heat_layer setting to help with heatmap dissipating on zoom\n",
    "# heat_layer.dissipating = False\n",
    "# heat_layer.max_intensity = 100\n",
    "# heat_layer.point_radius = 1\n",
    "\n",
    "White_povmap.add_layer(heat_layer_white)\n",
    "\n",
    "White_povmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "White_povmap = gmaps.figure()\n",
    "\n",
    "heat_layer_white = gmaps.heatmap_layer(pov_whitemap[[\"Lat\", \"Lng\"]], weights=pov_whitemap[\"white_rate\"], \n",
    "                                 dissipating=False, max_intensity=100,\n",
    "                                 point_radius = .5)\n",
    "\n",
    "# Adjust heat_layer setting to help with heatmap dissipating on zoom\n",
    "# heat_layer.dissipating = False\n",
    "# heat_layer.max_intensity = 100\n",
    "# heat_layer.point_radius = 1\n",
    "\n",
    "White_povmap.add_layer(heat_layer_white)\n",
    "\n",
    "White_povmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_pd.to_csv(\"cleanedCensus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with correct google Lat/Lat format\n",
    "google_Latlng = df1\n",
    "split = google_Latlng[\"LatLng\"].str.split(\"(\", n = 1, expand = True) \n",
    "split = split[1].str.split(\")\", n = 1, expand = True) \n",
    "google_Latlng[\"Lat/Lng\"]= split[0] \n",
    "  \n",
    "# Dropping old columns \n",
    "google_Latlng.drop(columns =[\"LatLng\"], inplace = True) \n",
    "google_Latlng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning up google_Latlng df\n",
    "google_Latlng = google_Latlng.loc[google_Latlng['Gender']== \"Overall\"]\n",
    "google_Latlng = google_Latlng.loc[google_Latlng['Race/Ethnicity'] == \"Overall\"]\n",
    "google_Latlng = google_Latlng.sort_values(['Value'],ascending=False)\n",
    "\n",
    "#google_Latlng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10\n",
    "google_top10 = google_Latlng.iloc[range(0,round(rows)),]\n",
    "\n",
    "#Bottom 10\n",
    "google_bottom10= google_Latlng.iloc[range(len(google_Latlng)- round(rows), len(google_Latlng))]\n",
    "google_bottom10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fast_food_count = []\n",
    "#base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json?query=Fast+Food&\"\n",
    "#token = 0\n",
    "#if token < 1:\n",
    "#    for i in google_top10[\"Lat/Lng\"]:\n",
    "#        params = {\n",
    "#        \"location\": i,\n",
    "#        \"keyword\": \"fast\",\n",
    "#        \"radius\": 35000,\n",
    "#        \"type\": \"restaurant\",\n",
    "#        \"key\": gkey}\n",
    "#        response = requests.get(base_url, params=params)\n",
    "\n",
    "        # convert response to json\n",
    "#        places_data = response.json()\n",
    "        # Print the json (pretty printed)\n",
    "        #print(json.dumps(places_data, indent=4, sort_keys=True))\n",
    "        \n",
    "#        fast_food_count.append(len(places_data[\"results\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Fast Food Column to Top 10 df\n",
    "top10['Fast Food Count'] = fast_food_count\n",
    "#top10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top10.to_csv(\"Top10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_food_countb = []\n",
    "base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json?query=Fast+Food&\"\n",
    "token = 0\n",
    "if token < 1:\n",
    "    for i in google_bottom10[\"Lat/Lng\"]:\n",
    "        params = {\n",
    "        \"location\": i,\n",
    "        \"keyword\": \"fast\",\n",
    "        \"radius\": 35000,\n",
    "        \"type\": \"restaurant\",\n",
    "        \"key\": gkey}\n",
    "        response = requests.get(base_url, params=params)\n",
    "\n",
    "        # convert response to json\n",
    "        places_data = response.json()\n",
    "        # Print the json (pretty printed)\n",
    "        #print(json.dumps(places_data, indent=4, sort_keys=True))\n",
    "        \n",
    "        fast_food_countb.append(len(places_data[\"results\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10['Fast Food Count'] = fast_food_count\n",
    "bottom10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10.to_csv(\"Bottom10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df['Race/Ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

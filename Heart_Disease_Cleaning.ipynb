{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Heart Disease Dataset from kaggle\n",
    "This dataset is for 2014 and provides the heart disease mortality rates for different\n",
    "ethnicities within the counties across the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "file = \"Data/Heart_Disease_Mortality_Data_Among_US_Adults_35_by_State_Territory_and_County.csv\"\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting Useless Columns\n",
    "df = df.drop(columns= [\"Year\", \"GeographicLevel\",\"DataSource\",\"Class\",'Topic',\"Data_Value_Type\",\n",
    "                       'Data_Value_Footnote_Symbol','Data_Value_Footnote','StratificationCategory1',\n",
    "                       'StratificationCategory2','TopicID','LocationID','Data_Value_Unit'])\n",
    "df = df.rename(columns={\"LocationAbbr\": \"State\", \"LocationDesc\": \"County\", \n",
    "                        \"Data_Value\": \"Value\", \"Stratification1\": \"Gender\", \n",
    "                        \"Stratification2\": \"Race/Ethnicity\", \"Location 1\": \"LatLng\"})\n",
    "\n",
    "# Dropping Rows that are missing data\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "df.to_csv(\"heart_partialclean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the latitude and longitude columns\n",
    "# We will use the latitude and longitude data for locations and google API\n",
    "split = df[\"LatLng\"].str.split(\"(\", n = 1, expand = True) \n",
    "split = split[1].str.split(\", \", n = 1, expand = True) \n",
    "splitLng = split[1].str.split(\")\", n = 1, expand = True) \n",
    "\n",
    "# making seperate first name column from new data frame \n",
    "df[\"Lat\"]= split[0] \n",
    "  \n",
    "# making seperate last name column from new data frame \n",
    "df[\"Lng\"]= splitLng[0] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "df.drop(columns =[\"LatLng\"], inplace = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by county\n",
    "county = pd.DataFrame(df)\n",
    "county = county.loc[county['Gender']== \"Overall\"]\n",
    "county = county.loc[county['Race/Ethnicity'] == \"Overall\"]\n",
    "\n",
    "# Reorder by rate of heart disease\n",
    "county = county.sort_values(['Value'],ascending=False)\n",
    "#.groupby(['State', 'County'])\n",
    "\n",
    "county.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by Ethnicity (White)\n",
    "white = pd.DataFrame(df)\n",
    "white = white.loc[white['Gender']== \"Overall\"]\n",
    "white = white.loc[white['Race/Ethnicity'] == \"White\"]\n",
    "white = white.sort_values(['State'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by Ethnicity (Black)\n",
    "black = pd.DataFrame(df)\n",
    "black = black.loc[black['Gender']== \"Overall\"]\n",
    "black = black.loc[black['Race/Ethnicity'] == \"Black\"]\n",
    "black = black.sort_values(['State'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by Ethnicity (Hispanic)\n",
    "hispanic = pd.DataFrame(df)\n",
    "hispanic = hispanic.loc[hispanic['Gender']== \"Overall\"]\n",
    "hispanic = hispanic.loc[hispanic['Race/Ethnicity'] == \"Hispanic\"]\n",
    "hispanic = hispanic.sort_values(['State'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by Ethnicity (American Indian)\n",
    "Indian = pd.DataFrame(df)\n",
    "Indian = Indian.loc[Indian['Gender']== \"Overall\"]\n",
    "Indian = Indian.loc[Indian['Race/Ethnicity'] == \"American Indian and Alaskan Native\"]\n",
    "Indian = Indian.sort_values(['State'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by Ethnicity (Asian)\n",
    "Asian = pd.DataFrame(df)\n",
    "Asian = Asian.loc[Asian['Gender']== \"Overall\"]\n",
    "Asian = Asian.loc[Asian['Race/Ethnicity'] == \"Asian and Pacific Islander\"]\n",
    "Asian = Asian.sort_values(['State'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to save all the things\n",
    "county.to_csv(\"countydata.csv\")\n",
    "white.to_csv(\"whitedata.csv\")\n",
    "black.to_csv(\"blackdata.csv\")\n",
    "hispanic.to_csv(\"hispanicdata.csv\")\n",
    "Indian.to_csv(\"indiandata.csv\")\n",
    "Asian.to_csv(\"asiandata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names\n",
    "#### State = State (self explanatory))\n",
    "#### County = County (self explanatory)\n",
    "#### Value = heart disease mortality rate.\n",
    "#### Gender = male, female, or overall = combing all genders together\n",
    "#### Race/Ethnicity = This provides the overall mortality rate ACROSS all ethnicities within a county and proviedes a weighted average of overall heart disease mortality. It also breaks it down by different ethnic groups\n",
    "#### Lat = Latitude of county\n",
    "#### Lng = Longitude of county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling Census data\n",
    "We will need data by county for populations of different ethnic groups\n",
    "\n",
    "See: https://github.com/CommerceDataService/census-wrapper for library documentation\n",
    "\n",
    "See: https://gist.github.com/afhaque/60558290d6efd892351c4b64e5c01e9b for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies that we may or may not need eventually\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from census import Census\n",
    "import gmaps\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Census & gmaps API Keys\n",
    "# Bring your own API keys!\n",
    "census_api = input(\"What's your Census API key?\")\n",
    "gkey = input (\"What's your Gmaps API key?\")\n",
    "c = Census(census_api, year=2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the documentation noted above, we can pull these variable names and get the data for each county in the US\n",
    "census_data_pop = c.acs5.get((\"NAME\", \"B02001_002E\", \"B02001_003E\", \"B02001_004E\",\n",
    "                              \"B02001_005E\",\"B02001_006E\", \"B02001_008E\", \n",
    "                              \"B03001_003E\", \"B01003_001E\"),{'for': 'county:*'})\n",
    "\n",
    "# Convert to DataFrame\n",
    "census_pop_pd = pd.DataFrame(census_data_pop)\n",
    "\n",
    "# Column renaming\n",
    "census_pop_pd = census_pop_pd.rename(columns={\"B02001_002E\": \"whitetot\",\n",
    "                                              \"B02001_003E\": \"blacktot\", \n",
    "                                              \"B02001_004E\": \"amerindtot\",\n",
    "                                              \"B02001_005E\": \"asiantot\",\n",
    "                                              \"B02001_006E\": \"nathawtot\", \n",
    "                                              \"B02001_008E\": \"multitot\", \n",
    "                                              \"B03001_003E\": \"hisptot\",\n",
    "                                              \"B01003_001E\" : \"totalpop\",\n",
    "                                              \"NAME\": \"Name\", \"county\": \"Country\"})\n",
    "# We'll manipulate the data a little now\n",
    "# We know that the data from the heart disease mortality dataset is \"per 100,000\"\n",
    "# Therefore we want to convert our population data into the same metric\n",
    "\n",
    "# finds a conversion factor for each county\n",
    "census_pop_pd[\"factor\"]= census_pop_pd[\"totalpop\"]/100000\n",
    "\n",
    "# Creates a per 100,000 population value for each racial/ethnic group\n",
    "census_pop_pd[\"white_perh\"] = census_pop_pd[\"whitetot\"] / census_pop_pd[\"factor\"]\n",
    "census_pop_pd[\"black_perh\"] = census_pop_pd[\"blacktot\"] / census_pop_pd[\"factor\"]\n",
    "census_pop_pd[\"amerind_perh\"] = census_pop_pd[\"amerindtot\"] / census_pop_pd[\"factor\"]\n",
    "census_pop_pd[\"asian_perh\"] = census_pop_pd[\"asiantot\"] / census_pop_pd[\"factor\"]\n",
    "census_pop_pd[\"nathaw_perh\"] = census_pop_pd[\"nathawtot\"] / census_pop_pd[\"factor\"]\n",
    "census_pop_pd[\"multi_perh\"] = census_pop_pd[\"multitot\"] / census_pop_pd[\"factor\"]\n",
    "census_pop_pd[\"hisp_perh\"] = census_pop_pd[\"hisptot\"] / census_pop_pd[\"factor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately the data location is in a \"County, State\" format\n",
    "# So we have to take WAY too much time and split that column. \n",
    "# And then we have to get rid of a space before the state name.\n",
    "# And then we have to match the state name to its abbreviation so we can match it later. \n",
    "# IF you were paying attention, a similar conversion was done above in the mortality data. \n",
    "# That conversion seemed to be much simpler than what we did here. So many ways to skin the data.\n",
    "\n",
    "# Import a csv file with a column of state names and their respective abbreviations\n",
    "states = pd.read_csv(\"state_abbreviations.csv\")\n",
    "\n",
    "# Make some space for the incoming data\n",
    "census_pop_pd[\"CountyName\"] = \"\"\n",
    "census_pop_pd[\"StateName\"] = \"\" \n",
    "census_pop_pd[\"State\"] = \"\"\n",
    "\n",
    "for i in range(0,len(census_pop_pd)):\n",
    "    st = census_pop_pd.Name[i].split(\",\")\n",
    "    census_pop_pd.CountyName[i] = st[0]\n",
    "    ct = st[1].split(\" \")\n",
    "    census_pop_pd.StateName[i] = ct[1]\n",
    "    for j in range(0, 50):\n",
    "        if census_pop_pd.StateName[i] == states.state[j]:\n",
    "            census_pop_pd.State[i] = states.abbreviation[j]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in Poverty Rate (Poverty Count / Population)\n",
    "# This will perhaps be used in an analysis... better too much data than not enough\n",
    "census_pop_pd[\"whiteperc\"] = 100*(census_pop_pd[\"whitetot\"].astype(int)/census_pop_pd[\"totalpop\"].astype(int))\n",
    "census_pop_pd[\"blackperc\"] = 100*(census_pop_pd[\"blacktot\"].astype(int)/census_pop_pd[\"totalpop\"].astype(int))\n",
    "census_pop_pd[\"amerindperc\"] = 100*(census_pop_pd[\"amerindtot\"].astype(int)/census_pop_pd[\"totalpop\"].astype(int))\n",
    "census_pop_pd[\"asianperc\"] = 100*(census_pop_pd[\"asiantot\"].astype(int)/census_pop_pd[\"totalpop\"].astype(int))\n",
    "census_pop_pd[\"nathawperc\"] = 100*(census_pop_pd[\"nathawtot\"].astype(int)/census_pop_pd[\"totalpop\"].astype(int))\n",
    "census_pop_pd[\"multiperc\"] = 100*(census_pop_pd[\"multitot\"].astype(int)/census_pop_pd[\"totalpop\"].astype(int))\n",
    "census_pop_pd[\"hispperc\"] = 100*(census_pop_pd[\"hisptot\"].astype(int)/census_pop_pd[\"totalpop\"].astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some useless columns\n",
    "census_pop_pd = census_pop_pd.drop(columns= [\"StateName\", \"Country\", \"Unnamed: 0\", \"state\", \"Name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving this Data!\n",
    "census_pop_pd.to_csv(\"CensusTotalPopulation_perH.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names\n",
    "#### totalpop = total population of each county\n",
    "#### whitetot = White population of each county\n",
    "#### blacktot = Black population of each county\n",
    "#### amerindtot = American Indian population of each county\n",
    "#### asiantot = Asian population of each county\n",
    "#### nathawtot = Native Hawaiian population of each county\n",
    "#### multitot= multi-racial population of each county\n",
    "#### hisptot = Hispanic population of each county\n",
    "#### factor = the factor needed to get the population data into per 100,000\n",
    "#### white_perh = White population per 100,000 \n",
    "#### black_perh = Black population per 100,000 \n",
    "#### amerind_perh = American Indian population per 100,000 \n",
    "#### asian_perh = Asian population population per 100,000 \n",
    "#### nathaw_perh = Native Hawaiian population per 100,000 \n",
    "#### multi_perh = multi-racial population per 100,000 \n",
    "#### hisp_perh = Hispanic population per 100,000 \n",
    "#### CountyName = Name of the county, separated from state\n",
    "#### State = state!\n",
    "#### whiteperc = White population percentage \n",
    "#### blackperc = Black population percentage\n",
    "#### amerindperc = American Indian population percentage\n",
    "#### asianperc = Asian population percentage\n",
    "#### nathawperc = Native Hawaiian population percentage\n",
    "#### multiperc = multi-racial population percentage\n",
    "#### hispperc = Hispanic population percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google API for Fast Food Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import heart disease DataFrame with correct google Lat/Lat format\n",
    "google_Latlng = pd.read_csv(\"Data/heart_partialclean.csv\")\n",
    "\n",
    "# Splitting Latitude and Longitude apart again \n",
    "# (can you tell these were done by different team members?)\n",
    "split = google_Latlng[\"LatLng\"].str.split(\"(\", n = 1, expand = True) \n",
    "split = split[1].str.split(\")\", n = 1, expand = True) \n",
    "google_Latlng[\"Lat/Lng\"]= split[0] \n",
    "  \n",
    "# Dropping old columns \n",
    "google_Latlng.drop(columns =[\"LatLng\"], inplace = True) \n",
    "google_Latlng.count()\n",
    "\n",
    "# Cleaning up google_Latlng df\n",
    "google_Latlng = google_Latlng.loc[google_Latlng['Gender']== \"Overall\"]\n",
    "google_Latlng = google_Latlng.loc[google_Latlng['Race/Ethnicity'] == \"Overall\"]\n",
    "google_Latlng = google_Latlng.sort_values(['Value'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating csv for fast food counts for all counties\n",
    "total_fast_food_count = []\n",
    "\n",
    "# A goog place to start\n",
    "base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json?query=Fast+Food&\"\n",
    "token = 0\n",
    "if token < 1:\n",
    "    for i in google_Latlng[\"Lat/Lng\"]:\n",
    "        params = {\n",
    "        \"location\": i,\n",
    "        \"keyword\": \"fast\",\n",
    "        \"radius\": 35000,\n",
    "        \"type\": \"restaurant\",\n",
    "        \"key\": gkey}\n",
    "        response = requests.get(base_url, params=params)\n",
    "\n",
    "        # convert response to json\n",
    "        places_data = response.json()\n",
    "        # Print the json (pretty printed)\n",
    "        # print(json.dumps(places_data, indent=4, sort_keys=True))\n",
    "        \n",
    "        total_fast_food_count.append(len(places_data[\"results\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the DataFrames together\n",
    "total_FF = google_Latlng\n",
    "total_FF[\"Fast Food Count\"] = total_fast_food_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Data!\n",
    "total_FF.to_csv(\"TotalFF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names \n",
    "###### (all self explanatory we hope!)\n",
    "#### State\n",
    "#### County\n",
    "#### Value\n",
    "#### Gender\n",
    "#### Rave/Ethnicity\n",
    "#### Lat\n",
    "#### Lng\n",
    "#### Fast Food Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google API for Hospital Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things you'll need!\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Importing and reading csv\n",
    "file = \"countydata.csv\"\n",
    "county_df = pd.read_csv(file)\n",
    "\n",
    "# Base URL needed to make the API call\n",
    "base_url = \"https://maps.googleapis.com/maps/api/place/textsearch/json\"\n",
    "\n",
    "target_type = \"hospital\"\n",
    "\n",
    "# Just in case youre running just this section or want to use a different key :)\n",
    "gkey = input(\"Enter an API key. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some places to hold the incoming data\n",
    "rating = []\n",
    "rating_count = []\n",
    "hospital_name = []\n",
    "county_name = []\n",
    "state_name = []\n",
    "\n",
    "# Start looping!\n",
    "for index, row in county_df.iterrows():\n",
    "    target_county = row[\"County\"]\n",
    "    target_state = row[\"State\"]\n",
    "    params = {\n",
    "        \"query\": f\"{target_county}, {target_state}\",\n",
    "        \"type\": target_type,\n",
    "        \"key\": gkey}\n",
    "    \n",
    "    response = requests.get(base_url, params=params).json()\n",
    "    \n",
    "    for i in range(len(response[\"results\"])):\n",
    "        rating.append(response[\"results\"][i][\"rating\"])\n",
    "        rating_count.append(response[\"results\"][i][\"user_ratings_total\"])\n",
    "        hospital_name.append(response[\"results\"][i][\"name\"])\n",
    "        county_name.append(row[\"County\"])\n",
    "        state_name.append(row[\"State\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of all the data acquired above\n",
    "data = {\"County\": county_name, \"State\": state_name, \"Hospital Name\": hospital_name, \n",
    "        \"Rating\": rating, \"Rating Count\": rating_count}\n",
    "\n",
    "# Turn the dictionary into a dataframe\n",
    "hospital_data_df = pd.DataFrame(data, columns=[\"County\", \"State\", \"Hospital Name\", \"Rating\", \"Rating Count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names\n",
    "#### County\n",
    "#### State\n",
    "#### Hospital Name\n",
    "#### Rating = How much people like this hospital. \n",
    "#### Rating Count = Number of ratings used to go into the calculation of a rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Data\n",
    "hospital_data_df.to_csv(r\"cleaned_hospital_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the data is saved from the Hospital API, we want to do some counting\n",
    "# Drop some columns cuz we don't need them righ tnow\n",
    "columns = [\"List_ID\", \"Hospital Name\", \"Rating\", \"Rating Count\"]\n",
    "hospital_data_df.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a full location name for each row\n",
    "hospital_data_df[\"Full Location\"] = hospital_data_df[\"County\"] + \" \" + hospital_data_df[\"State\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to see how many different \"Full Locations\" names we have\n",
    "result = hospital_data_df.groupby(\"Full Location\").first()\n",
    "\n",
    "result[\"Hospital Count\"] = hospital_data_df[\"Full Location\"].value_counts()\n",
    "result.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then drop the \"Full Location\" column because we wont need it in ANY of the analyses\n",
    "result = result.drop(\"Full Location\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Data\n",
    "result.to_csv(r\"number_of_hospitals_per_county.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names\n",
    "#### County\n",
    "#### State\n",
    "#### Hospital count = number of hospitals located in each county (within a 21 mile radius that is)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
